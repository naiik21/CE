{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification with numpy NN implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset in csv format. (https://www.kaggle.com/datasets/arshid/iris-flower-dataset)\n",
    "\n",
    "Load the dataset into a variable **iris**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([6.7, 2.5, 5.8, 1.8]), array([6.5, 2.8, 4.6, 1.5]), array([6.9, 3.1, 5.1, 2.3]), array([6.5, 3.2, 5.1, 2. ]), array([5.1, 3.4, 1.5, 0.2]), array([6.4, 2.7, 5.3, 1.9]), array([5.2, 2.7, 3.9, 1.4]), array([5.7, 2.8, 4.5, 1.3]), array([6.3, 2.5, 4.9, 1.5]), array([5.7, 4.4, 1.5, 0.4]), array([5.8, 4. , 1.2, 0.2]), array([4.5, 2.3, 1.3, 0.3]), array([6.5, 3. , 5.5, 1.8]), array([5.3, 3.7, 1.5, 0.2]), array([6.7, 3.3, 5.7, 2.1]), array([7.7, 2.6, 6.9, 2.3]), array([6.3, 3.3, 6. , 2.5]), array([4.8, 3. , 1.4, 0.3]), array([6.2, 2.9, 4.3, 1.3]), array([4.9, 3.1, 1.5, 0.2]), array([5.4, 3.7, 1.5, 0.2]), array([6. , 2.9, 4.5, 1.5]), array([6.7, 3.3, 5.7, 2.5]), array([6.4, 2.8, 5.6, 2.1]), array([5.5, 2.4, 3.7, 1. ]), array([5.4, 3.4, 1.7, 0.2]), array([5.1, 3.5, 1.4, 0.2]), array([6.7, 3. , 5. , 1.7]), array([6.3, 2.3, 4.4, 1.3]), array([6.7, 3.1, 5.6, 2.4]), array([7.7, 3.8, 6.7, 2.2]), array([6.4, 3.2, 5.3, 2.3]), array([4.9, 2.5, 4.5, 1.7]), array([6. , 2.2, 5. , 1.5]), array([5.6, 2.5, 3.9, 1.1]), array([5.1, 2.5, 3. , 1.1]), array([4.7, 3.2, 1.3, 0.2]), array([6.3, 3.4, 5.6, 2.4]), array([6.1, 2.6, 5.6, 1.4]), array([5.1, 3.5, 1.4, 0.3]), array([6.3, 2.9, 5.6, 1.8]), array([6.3, 2.5, 5. , 1.9]), array([6.2, 3.4, 5.4, 2.3]), array([5.1, 3.8, 1.9, 0.4]), array([7.7, 3. , 6.1, 2.3]), array([5.5, 2.4, 3.8, 1.1]), array([5. , 3.5, 1.3, 0.3]), array([7.2, 3. , 5.8, 1.6]), array([4.9, 3.6, 1.4, 0.1]), array([7.2, 3.6, 6.1, 2.5]), array([4.4, 3. , 1.3, 0.2]), array([6.4, 2.8, 5.6, 2.2]), array([5.5, 2.3, 4. , 1.3]), array([7.7, 2.8, 6.7, 2. ]), array([6.5, 3. , 5.2, 2. ]), array([7.1, 3. , 5.9, 2.1]), array([5.2, 3.4, 1.4, 0.2]), array([5.7, 2.9, 4.2, 1.3]), array([6.1, 2.8, 4. , 1.3]), array([5.8, 2.6, 4. , 1.2]), array([4.4, 2.9, 1.4, 0.2]), array([5. , 2. , 3.5, 1. ]), array([5. , 3.4, 1.6, 0.4]), array([4.8, 3.1, 1.6, 0.2]), array([5.2, 3.5, 1.5, 0.2]), array([5.8, 2.7, 5.1, 1.9]), array([7.9, 3.8, 6.4, 2. ]), array([5.1, 3.8, 1.6, 0.2]), array([4.6, 3.2, 1.4, 0.2]), array([5. , 3.4, 1.5, 0.2]), array([6.8, 3.2, 5.9, 2.3]), array([4.8, 3. , 1.4, 0.1]), array([7.3, 2.9, 6.3, 1.8]), array([5.2, 4.1, 1.5, 0.1]), array([5.7, 2.6, 3.5, 1. ]), array([5. , 3.2, 1.2, 0.2]), array([7.6, 3. , 6.6, 2.1]), array([5.8, 2.8, 5.1, 2.4]), array([5.5, 3.5, 1.3, 0.2]), array([6.9, 3.2, 5.7, 2.3]), array([5.4, 3. , 4.5, 1.5]), array([6.4, 3.1, 5.5, 1.8]), array([5.9, 3. , 4.2, 1.5]), array([6.1, 3. , 4.9, 1.8]), array([5.4, 3.4, 1.5, 0.4]), array([5.7, 2.5, 5. , 2. ]), array([6.2, 2.2, 4.5, 1.5]), array([4.6, 3.6, 1. , 0.2]), array([5.8, 2.7, 5.1, 1.9]), array([5.6, 2.8, 4.9, 2. ]), array([5.8, 2.7, 4.1, 1. ]), array([5.9, 3. , 5.1, 1.8]), array([6.3, 2.7, 4.9, 1.8]), array([4.6, 3.1, 1.5, 0.2]), array([6. , 2.2, 4. , 1. ]), array([6. , 3.4, 4.5, 1.6]), array([6.3, 2.8, 5.1, 1.5]), array([6.3, 3.3, 4.7, 1.6]), array([5.6, 3. , 4.5, 1.5]), array([6.7, 3.1, 4.7, 1.5]), array([4.8, 3.4, 1.9, 0.2]), array([6. , 3. , 4.8, 1.8]), array([5. , 3.3, 1.4, 0.2]), array([5.5, 2.6, 4.4, 1.2]), array([5.5, 4.2, 1.4, 0.2]))\n",
      "(np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(0), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(0), np.int64(2), np.int64(2), np.int64(2), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(1), np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(2), np.int64(2), np.int64(2), np.int64(0), np.int64(2), np.int64(1), np.int64(0), np.int64(2), np.int64(0), np.int64(2), np.int64(0), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(0), np.int64(2), np.int64(0), np.int64(1), np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(0), np.int64(2), np.int64(1), np.int64(0), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(0), np.int64(1), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(2), np.int64(0), np.int64(1), np.int64(0))\n",
      "(array([6.1, 2.9, 4.7, 1.4]), array([5.6, 2.9, 3.6, 1.3]), array([4.4, 3.2, 1.3, 0.2]), array([4.3, 3. , 1.1, 0.1]), array([6.6, 2.9, 4.6, 1.3]), array([7.2, 3.2, 6. , 1.8]), array([5.5, 2.5, 4. , 1.3]), array([6.5, 3. , 5.8, 2.2]), array([6. , 2.7, 5.1, 1.6]), array([6.1, 3. , 4.6, 1.4]), array([4.8, 3.4, 1.6, 0.2]), array([5.1, 3.3, 1.7, 0.5]), array([5.8, 2.7, 3.9, 1.2]), array([6.6, 3. , 4.4, 1.4]), array([5.4, 3.9, 1.7, 0.4]), array([5.6, 2.7, 4.2, 1.3]), array([4.9, 3.1, 1.5, 0.1]), array([5. , 3.5, 1.6, 0.6]), array([7.4, 2.8, 6.1, 1.9]), array([5.6, 3. , 4.1, 1.3]), array([5.1, 3.7, 1.5, 0.4]), array([7. , 3.2, 4.7, 1.4]), array([6.9, 3.1, 5.4, 2.1]), array([6.9, 3.1, 4.9, 1.5]), array([6.1, 2.8, 4.7, 1.2]), array([5.7, 3. , 4.2, 1.2]), array([6.2, 2.8, 4.8, 1.8]), array([5. , 3.6, 1.4, 0.2]), array([6.7, 3. , 5.2, 2.3]), array([5.7, 3.8, 1.7, 0.3]), array([4.7, 3.2, 1.6, 0.2]), array([5. , 2.3, 3.3, 1. ]), array([5.4, 3.9, 1.3, 0.4]), array([4.6, 3.4, 1.4, 0.3]), array([5.1, 3.8, 1.5, 0.3]), array([5.9, 3.2, 4.8, 1.8]), array([6.8, 2.8, 4.8, 1.4]), array([4.9, 3. , 1.4, 0.2]), array([6.4, 2.9, 4.3, 1.3]), array([6.8, 3. , 5.5, 2.1]), array([6.4, 3.2, 4.5, 1.5]), array([5.7, 2.8, 4.1, 1.3]), array([4.9, 2.4, 3.3, 1. ]), array([5. , 3. , 1.6, 0.2]), array([6.7, 3.1, 4.4, 1.4]))\n",
      "(np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(2), np.int64(1), np.int64(0), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(2), np.int64(0), np.int64(2), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "# y format is a vector with 3 different values \"0, 1, 2\" instead of the \"versicolor, virginica, setosa\" labels\n",
    "\n",
    "import random\n",
    "\n",
    "def data_splitter(X, y, train=0.8, shuffle=True):\n",
    "  cut = int(len(y)*train)\n",
    "  zipped_data = list(zip(X,y))\n",
    "  if shuffle:\n",
    "    random.shuffle(zipped_data)\n",
    "  X_train, y_train = zip(*zipped_data[0:cut])\n",
    "  X_test, y_test = zip(*zipped_data[cut:])\n",
    "  return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_splitter(X, y, 0.7)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define abstract class layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer():\n",
    "    def __init__(self):\n",
    "        self.input= None\n",
    "        self.output= None\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    def backward(self):\n",
    "        pass\n",
    "    \n",
    "    def update_parametres(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_layer():\n",
    "    def __init__(self, input_dimensions, output_dimensions):\n",
    "        self.W=2*np.random.rand(input_dimensions, output_dimensions)-1\n",
    "        self.B=np.random.rand(1, output_dimensions)\n",
    "          \n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        return x @ self.W+self.B\n",
    "    \n",
    "    def backward(self,error):\n",
    "        self.dW= error @ np.transpose(self.x) \n",
    "        self.dB= error.sum(axis=0)\n",
    "        return error @ np.transpose(self.W)\n",
    "    \n",
    "    def update_parametres(self, lr):\n",
    "        self.W=self.W - lr * self.dW\n",
    "        self.B= self.B- lr * self.dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define activation layers and input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu_layer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.Z=np.maximum(0,x)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self,error):\n",
    "        return error * (self.Z > 0)\n",
    "    \n",
    "    def update_parametres(self, lr):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class input_layer():\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size= input_size\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return x\n",
    "    \n",
    "    def backward(self,error):\n",
    "        return error\n",
    "    \n",
    "    def update_parametres(self, lr):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function/optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model design\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'linear_layer' object has no attribute 'dW'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[429], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#print(error)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward(error)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_parametres\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[429], line 24\u001b[0m, in \u001b[0;36mNN_model.update_parametres\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_parametres\u001b[39m(\u001b[38;5;28mself\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequencial:\n\u001b[0;32m---> 24\u001b[0m         \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_parametres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[427], line 16\u001b[0m, in \u001b[0;36mlinear_layer.update_parametres\u001b[0;34m(self, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_parametres\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdW\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdB\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'linear_layer' object has no attribute 'dW'"
     ]
    }
   ],
   "source": [
    "class NN_model():\n",
    "    def __init__(self):\n",
    "        self.sequencial= [input_layer(4),\n",
    "                        linear_layer(4,3),\n",
    "                        Relu_layer(),\n",
    "                        #linear_layer(100,100),\n",
    "                        #Relu_layer(),\n",
    "                        linear_layer(3,3)]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.sequencial:\n",
    "            y= layer.forward(x)\n",
    "            x= y\n",
    "        return y\n",
    "    \n",
    "    def backward(self, error):\n",
    "        for layer in np.flip(self.sequencial):\n",
    "            y = layer.backward(error)\n",
    "            error= y\n",
    "            return y\n",
    "        \n",
    "    def update_parametres(self, learning_rate=0.03):\n",
    "        for layer in self.sequencial:\n",
    "            layer.update_parametres(learning_rate)\n",
    "        \n",
    "model= NN_model()\n",
    "\"\"\"\n",
    "y_pred=model.forward(np.array([-2,1,4,-8]).reshape(1,4))\n",
    "print(y_pred)\n",
    "\n",
    "y_real= np.array([1,0])\n",
    "\n",
    "error= 2*np.abs(y_pred-y_real)\n",
    "\n",
    "model.backword(error)\n",
    "\"\"\"\n",
    "y_pred=model.forward(np.array(X_train))\n",
    "#print(y_pred)\n",
    "\n",
    "y_real= np.array([0,1,2])\n",
    "\n",
    "error= 2*np.abs(y_pred-y_real)\n",
    "#print(error)\n",
    "\n",
    "model.backward(error)\n",
    "\n",
    "model.update_parametres()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef train(model, x, y):\\n    for x_batch,. y_batch in (x,y):\\n        y_pred=model.forward(batch)\\n        error= (y-y_pred)\\n'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def train(model, x, y):\n",
    "    for x_batch,. y_batch in (x,y):\n",
    "        y_pred=model.forward(batch)\n",
    "        error= (y-y_pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
